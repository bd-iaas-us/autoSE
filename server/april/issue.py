import os
import sys
import tempfile
import time
from datetime import datetime, timedelta
from threading import Lock, Thread
from typing import Dict
from urllib.parse import urlparse

import git
#from fastapi.responses import JSONResponse
from fastapi import HTTPException
from rag import RagDocument
from task import Task, TaskStatus

try:
    swe_dir = os.environ["SWE_DIR"]
except Exception as _:
    raise Exception("SWE_DIR is not set...")

sys.path.append(swe_dir)
import run
from logger import init_logger

logger = init_logger(__name__)

# All the project related files, include repository, files generated by agent
# are saved in a folder generated by owner&repo under WORK_SPACE
WORK_SPACE = tempfile.gettempdir() + "/ailint/workspace"

# Python built-in dict is multi-thread safe for single operation
# But not for operations like: dict[i] = dick[j], dict[i] += 1 etc
# Add a mutex to guard tasks for peaceful mind
tasks_mutex = Lock()
tasks: Dict[str, Task] = {}


class SWEAgent:

    def __init__(self, data_path, repo_path, ailint_task, model):
        '''
        data_path: the path to the issue file, should be end with .md or .txt
        repo_path: the path to the repo directory, should be clean except the issue file
        '''
        self.data_path = data_path
        self.repo_path = repo_path
        #choose gpt4 or gpt4o
        if model.startswith("openai:"):
            self.model_name = model.split(":")[1]
        else:
            self.model_name = model
        self.ailint_task = ailint_task

    def run(self):
        '''
        traj_dir has following structure:
            patches: contain diff files, .patch
            .jsonl: model_stats
            args.yaml: run arguments
            .traj: execution environment, trajectory and history
        '''
        script_args = run.get_args([
            '--model_name', self.model_name, '--data_path', self.data_path,
            '--repo_path', self.repo_path, '--config_file',
            'config/default_from_url.yaml', '--apply_patch_locally'
        ])
        run_main = run.Main(script_args, self.ailint_task)
        Thread(target=run_main.main).start()
        return os.path.join(swe_dir, run_main.traj_dir)


# The function generate a suffix based upon the datetime it is called
def gen_folder_suffix():
    return datetime.now().strftime("%m-%d-%Y_%H-%M-%S")


# The function get the path where the repository is cloned
# the path is created if not exists
def get_repo_folder(owner: str, repo: str, suffix=""):
    # Specify the path where you want to create the folder
    folder_path = WORK_SPACE + f'/{owner}/{repo}'
    if len(suffix) > 0:
        folder_path = folder_path + "_" + suffix

    if not os.path.exists(folder_path):
        # Create the folder
        os.makedirs(folder_path, exist_ok=True)
        return False, folder_path
    return True, folder_path


# The function get the path where the data is saved
# the path is created if not exists
def get_data_folder(owner: str, repo: str, suffix=""):
    # Specify the path where you want to create the folder
    folder_path = WORK_SPACE + f'/{owner}/{repo}_data'
    if len(suffix) > 0:
        folder_path = folder_path + "_" + suffix

    if not os.path.exists(folder_path):
        # Create the folder
        os.makedirs(folder_path, exist_ok=True)
        return False, folder_path
    return True, folder_path


# The function retrieve the owner and repository parts from url object
def get_owner_repo(url_obj):
    path = url_obj.path
    tokens = path.split("/")
    i = 0
    if len(tokens[i]) == 0:
        i += 1
    return tokens[i], tokens[i + 1]


# The function generate the github API url, like
#   https://api.github.com/repos/{owner}/{repo}
#  NOTE: The function is not used for now, but keep it
#  in case we call github api in the future
def gen_github_api_url(url_obj):
    github_api = url_obj.hostname
    # If the host name starts with "www.", trim it
    if github_api.startswith("www."):
        github_api = github_api[4:]
    # Assemble the github api url
    github_api = "api." + github_api[4:]
    owner, repo = get_owner_repo(url_obj)
    return f'{url_obj.scheme}://{github_api}/repos/{owner}/{repo}/'


# "tasks" is a built-in dict object and thread-safe for single
# operations like tasks[taskId], but not for the task in "tasks"
# Here we don't use a global lock to guard "tasks",
def get_task(taskId):
    with tasks_mutex:
        logger.info(f"get_task !!! {tasks}")
        if taskId in tasks:
            return tasks[taskId]
    return None


def add_task(task: Task):
    with tasks_mutex:
        # task id is a UUID, dup not checked here
        tasks[task.id] = task


# The handler function retrieve the task
def handle_task(taskId) -> tuple[str, str]:
    """
    return a tuple[status, patch]
    """
    logger.info(f'getting task info for taskId: {taskId}')
    #outer logic will make sure taskId exists.
    task = get_task(taskId)
    # get patch
    patch_file = task.get_patch_file()
    patch = ""
    if patch_file is not None:
        logger.info(f'reading patch file: {patch_file}')
        with open(patch_file, 'r') as f:
            patch = f.read()

    return (task.get_status().name, patch)


# Only support "https:" scheme for the moment
def clone_repo(url_obj, token=None, folder_suffix=""):
    owner, repo = get_owner_repo(url_obj)
    repo_exist, repo_folder = get_repo_folder(owner, repo, folder_suffix)
    if not repo_exist:
        url = f'{url_obj.scheme}://'
        if token is not None and len(token) > 0:
            url += f'oauth2:{token}@'
        url += f'{url_obj.hostname}/{owner}/{repo}'
        git.Git().clone(url, repo_folder)
        logger.info(f'clone: {url}')
        return True, repo_folder
    return False, repo_folder


# The handler function for repo prompt
def handle_prompt(request) -> str:
    """
    The worker function to handle a dev request for a  project based
    prompt
    The promptObj contains "repo", "token" and "prompt"
    create swe-agent task
    return taskID
    """
    new_task = Task(request.prompt)
    logger.info(f'new_task: {new_task}')
    add_task(new_task)
    try:
        url_obj = urlparse(request.repo)
    except Exception as e:
        raise HTTPException(status_code=400, detail=f"{e}")

    success, repo_folder = clone_repo(url_obj, request.token,
                                      gen_folder_suffix())
    if not success:
        #return JSONResponse(status_code=400, content={'message': "The repo specified exists or cannot be cloned"})
        raise HTTPException(
            status_code=400,
            detail="the repo specified exists or cannot be cloned")

    prompt_file_name = f'{repo_folder}/prompt_{new_task.get_id()}.txt'
    try:
        with open(prompt_file_name, "w") as prompt_file:
            prompt_file.write(request.prompt + "\n\n")

            # Use Rag if topic is contained in the request
            if request.topic:
                prompt_file.write("Related Documents below:\n")
                # Add the top 2 documents into the prompt
                rag = RagDocument()
                related_docs = rag.get_docs(request.prompt, request.topic)
                related_docs = related_docs[:2]
                for idx, doc in enumerate(related_docs, start=1):
                    prompt_file.write(f"Document_{idx}: {doc}\n\n")
                logger.info(f"prompt_file_name, {prompt_file_name}")

    except Exception as e:
        raise HTTPException(status_code=500,
                            detail=f"Error writing to prompt file: {e}")

    new_task.set_status(TaskStatus.RUNNING)

    try:
        agent = SWEAgent(prompt_file_name, repo_folder, new_task,
                         request.model)
        result_dir = agent.run()
        new_task.set_data_dir(result_dir)
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"{e}")
    return new_task.get_id()


# NOTE: The function can not be called with gen_history_data at the same time
def gen_history_data(taskId: str):
    #outer logic will make sure taskId exists.
    task = get_task(taskId)
    idx = 0
    last_update = datetime.now()
    logger.info(
        f'----------- start processing the history for task {task} at {datetime.now()}'
    )
    while True:
        n = task.get_history_len()
        if n == idx:
            if datetime.now() - last_update > timedelta(minutes=2):
                logger.warn("client waits too long, quit...")
                return
            #TODO: use cond lock to replace time.sleep
            time.sleep(0.2)
            continue
        last_update = datetime.now()
        for i in range(idx, n):
            item = task.get_history(i)
            yield str(item["action"])

            #swe-agent could run into error. in this case. should set status to ERROR
            if "submit" in item["action"]:
                task.set_status(TaskStatus.DONE)
                return
            if "exit_cost" in item["action"]:
                task.set_status(TaskStatus.EXIT_COST)
                return
        idx = n
